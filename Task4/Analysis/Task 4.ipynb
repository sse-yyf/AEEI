{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "155a30a4",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2d5026a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad61e10",
   "metadata": {},
   "source": [
    "# Exercise 1 & 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5aac68",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "b22cc3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../raw/growthdata92_02.csv\",index_col=0)\n",
    "x = df.drop(['iso3','ln_y','growth'], axis=1)\n",
    "y1 = df['ln_y']\n",
    "y2 = df['growth']\n",
    "df_0211 = pd.read_csv(\"../raw/growthdata02_11.csv\",index_col=0)\n",
    "x_0211 = df_0211.drop(['iso3','ln_y','growth'], axis=1)\n",
    "y1_0211 = df_0211['ln_y']\n",
    "y2_0211 = df_0211['growth']\n",
    "\n",
    "# get train set and test set\n",
    "x1_train,x1_test,y1_train,y1_test = train_test_split(x,y1,test_size = 0.2)\n",
    "x2_train,x2_test,y2_train,y2_test = train_test_split(x,y2,test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0834c798",
   "metadata": {},
   "source": [
    "## Subset Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "768945f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('gvmnt_c', 'ext_bal', 'inf_mort', 'age_dep_young', 'urban', 'parliamentary', 'presidential', 'voice', 'effectiveness')\n",
      "0.8391666435030196\n",
      "MAE for naive predictor: 0.0\n",
      "RMSE for kitchen sink predictor: 0.3197719013920757\n",
      "Performance on test set: 0.3688318516459661\n",
      "Performance on 02-11 dataset: 0.36448672851176045\n"
     ]
    }
   ],
   "source": [
    "reg = linear_model.LinearRegression()\n",
    "\n",
    "# ln_y\n",
    "sfs = SequentialFeatureSelector(reg,k_features = (2,x1_train.shape[1]),forward=True, floating=False, cv=10\n",
    "                               # ,verbose=2         # show the process\n",
    "                               )\n",
    "sfs.fit(x1_train,y1_train)\n",
    "selected_features = list(sfs.k_feature_names_)\n",
    "print(sfs.k_feature_names_)\n",
    "print(sfs.k_score_)\n",
    "\n",
    "# Ex1\n",
    "x1_selected = x1_train[selected_features]\n",
    "reg.fit(x1_selected,y1_train)\n",
    "mean = pd.DataFrame(np.mean(x1_selected)).transpose()\n",
    "naive_y_pre = reg.predict(mean)\n",
    "mae = abs(naive_y_pre[0] - np.mean(y1_train))\n",
    "print('MAE for naive predictor: ' + str(mae))\n",
    "sink_y_pre = reg.predict(x[selected_features])\n",
    "sink_rmse = np.sqrt(mean_squared_error(y1, sink_y_pre))\n",
    "print('RMSE for kitchen sink predictor: '+ str(sink_rmse))\n",
    "test_y_pre = reg.predict(x1_test[selected_features])\n",
    "test_rmse = np.sqrt(mean_squared_error(y1_test, test_y_pre))\n",
    "print('Performance on test set: ' + str(test_rmse))\n",
    "\n",
    "# Ex2\n",
    "test_y_0211_pre = reg.predict(x_0211[selected_features])\n",
    "test_rmse_0211 = np.sqrt(mean_squared_error(y1_0211, test_y_0211_pre))\n",
    "print('Performance on 02-11 dataset: ' + str(test_rmse_0211))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "85992dff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('inflation', 'regulation')\n",
      "0.23406080537112647\n",
      "MAE for naive predictor: 6.938893903907228e-18\n",
      "RMSE for kitchen sink predictor: 0.023016278099988886\n",
      "Performance on test set: 0.024087599661712887\n",
      "Performance on 02-11 dataset: 0.041263384225615665\n"
     ]
    }
   ],
   "source": [
    "sfs.fit(x2_train,y2_train)\n",
    "print(sfs.k_feature_names_)\n",
    "print(sfs.k_score_)\n",
    "\n",
    "# Ex1\n",
    "x2_selected = x2_train[selected_features]\n",
    "reg.fit(x2_selected,y2_train)\n",
    "mean = pd.DataFrame(np.mean(x2_selected)).transpose()\n",
    "naive_y_pre = reg.predict(mean)\n",
    "mae = abs(naive_y_pre[0] - np.mean(y2_train))\n",
    "print('MAE for naive predictor: ' + str(mae))\n",
    "sink_y_pre = reg.predict(x[selected_features])\n",
    "rmse = np.sqrt(mean_squared_error(y2, sink_y_pre))\n",
    "print('RMSE for kitchen sink predictor: '+ str(rmse))\n",
    "test_y_pre = reg.predict(x2_test[selected_features])\n",
    "test_rmse = np.sqrt(mean_squared_error(y2_test, test_y_pre))\n",
    "print('Performance on test set: ' + str(test_rmse))\n",
    "\n",
    "# Ex2\n",
    "test_y_0211_pre = reg.predict(x_0211[selected_features])\n",
    "test_rmse_0211 = np.sqrt(mean_squared_error(y2_0211, test_y_0211_pre))\n",
    "print('Performance on 02-11 dataset: ' + str(test_rmse_0211))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9f271d",
   "metadata": {},
   "source": [
    "## Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea3adc9f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'linear_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-8f3acaded108>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0malpha\u001b[0m \u001b[1;32min\u001b[0m \u001b[0malphas\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mridge\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlinear_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRidge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mridge\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx1_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my1_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mridge_scores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'linear_model' is not defined"
     ]
    }
   ],
   "source": [
    "alphas = np.logspace(0, 3, 100) \n",
    "ridge_scores = []\n",
    "\n",
    "for alpha in alphas:\n",
    "    ridge = linear_model.Ridge(alpha=alpha)\n",
    "    scores = cross_val_score(ridge, x1_train, y1_train, cv=10)\n",
    "    ridge_scores.append(np.mean(scores))\n",
    "best_alpha_index = np.argmax(ridge_scores)  \n",
    "best_alpha = alphas[best_alpha_index]  \n",
    "best_score = ridge_scores[best_alpha_index] \n",
    "print('Best score: ' + str(best_score))\n",
    "print('Best alpha: ' + str(best_alpha))\n",
    "\n",
    "# Ex1\n",
    "ridge = linear_model.Ridge(alpha = best_alpha)\n",
    "ridge.fit(x1_train, y1_train)\n",
    "mean = pd.DataFrame(np.mean(x1_train)).transpose()\n",
    "naive_y_pre = ridge.predict(mean)\n",
    "mae = abs(naive_y_pre[0] - np.mean(y1_train))\n",
    "print('MAE for naive predictor: ' + str(mae))\n",
    "sink_y_pre = ridge.predict(x)\n",
    "rmse = np.sqrt(mean_squared_error(y1, sink_y_pre))\n",
    "print('RMSE for kitchen sink predictor: '+ str(rmse))\n",
    "test_y_pre = ridge.predict(x1_test)\n",
    "test_rmse = np.sqrt(mean_squared_error(y1_test, test_y_pre))\n",
    "print('Performance on test set: ' + str(test_rmse))\n",
    "\n",
    "# Ex2\n",
    "test_y_0211_pre = ridge.predict(x_0211)\n",
    "test_rmse_0211 = np.sqrt(mean_squared_error(y1_0211, test_y_0211_pre))\n",
    "print('Performance on 02-11 dataset: ' + str(test_rmse_0211))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "81e124da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.14702797414347418\n",
      "Best alpha: 200.9233002565048\n",
      "MAE for naive predictor: 3.469446951953614e-18\n",
      "RMSE for kitchen sink predictor: 0.02349818064266689\n",
      "Performance on test set: 0.025098406461586974\n",
      "Performance on 02-11 dataset: 0.031190275082630475\n"
     ]
    }
   ],
   "source": [
    "ridge_scores = []\n",
    "for alpha in alphas:\n",
    "    ridge = linear_model.Ridge(alpha=alpha)\n",
    "    scores = cross_val_score(ridge, x2_train, y2_train, cv=10)\n",
    "    ridge_scores.append(np.mean(scores))\n",
    "\n",
    "best_alpha_index = np.argmax(ridge_scores)  \n",
    "best_alpha = alphas[best_alpha_index]  \n",
    "best_score = ridge_scores[best_alpha_index] \n",
    "print('Best score: ' + str(best_score))\n",
    "print('Best alpha: ' + str(best_alpha))\n",
    "\n",
    "# Ex1\n",
    "ridge = linear_model.Ridge(alpha = best_alpha)\n",
    "ridge.fit(x2_train, y2_train)\n",
    "mean = pd.DataFrame(np.mean(x2_train)).transpose()\n",
    "naive_y_pre = ridge.predict(mean)\n",
    "mae = abs(naive_y_pre[0] - np.mean(y2_train))\n",
    "print('MAE for naive predictor: ' + str(mae))\n",
    "sink_y_pre = ridge.predict(x)\n",
    "rmse = np.sqrt(mean_squared_error(y2, sink_y_pre))\n",
    "print('RMSE for kitchen sink predictor: '+ str(rmse))\n",
    "test_y_pre = ridge.predict(x2_test)\n",
    "test_rmse = np.sqrt(mean_squared_error(y2_test, test_y_pre))\n",
    "print('Performance on test set: ' + str(test_rmse))\n",
    "\n",
    "# Ex2\n",
    "test_y_0211_pre = ridge.predict(x_0211)\n",
    "test_rmse_0211 = np.sqrt(mean_squared_error(y2_0211, test_y_0211_pre))\n",
    "print('Performance on 02-11 dataset: ' + str(test_rmse_0211))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09bb209",
   "metadata": {},
   "source": [
    "## Principal Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "9f80fd51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9128423223766344\n",
      "RMSE for kitchen sink predictor: 0.31153937801432424\n",
      "Performance on test set: 0.37905536112634947\n",
      "Performance on 02-11 dataset: 0.35777856278611614\n"
     ]
    }
   ],
   "source": [
    "# PCA\n",
    "pca = PCA(copy = True)\n",
    "pca_fit = pca.fit(x1_train)\n",
    "x1_pca = pca.fit_transform(x1_train)\n",
    "reg = linear_model.LinearRegression()\n",
    "pcreg = reg.fit(x1_pca,y1_train)\n",
    "print(reg.score(x1_pca,y1_train))\n",
    "\n",
    "# Ex1\n",
    "x_pca = pca_fit.transform(x)\n",
    "sink_y_pre = pcreg.predict(x_pca)\n",
    "rmse = np.sqrt(mean_squared_error(y1, sink_y_pre))\n",
    "print('RMSE for kitchen sink predictor: '+ str(rmse))\n",
    "x1_test_pca = pca_fit.transform(x1_test)\n",
    "test_y_pre = pcreg.predict(x1_test_pca)\n",
    "test_rmse = np.sqrt(mean_squared_error(y1_test, test_y_pre))\n",
    "print('Performance on test set: ' + str(test_rmse))\n",
    "\n",
    "# Ex2\n",
    "x_0211_pca = pca_fit.transform(x_0211)\n",
    "test_y_0211_pre = pcreg.predict(x_0211_pca)\n",
    "test_rmse_0211 = np.sqrt(mean_squared_error(y1_0211, test_y_0211_pre))\n",
    "print('Performance on 02-11 dataset: ' + str(test_rmse_0211))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "db694261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5177739976408676\n",
      "RMSE for kitchen sink predictor: 0.02110496580963439\n",
      "Performance on test set: 0.024420443988734913\n",
      "Performance on 02-11 dataset: 0.03728999626681858\n"
     ]
    }
   ],
   "source": [
    "pca_fit = pca.fit(x2_train)\n",
    "x2_pca = pca.fit_transform(x2_train)\n",
    "reg = linear_model.LinearRegression()\n",
    "pcreg = reg.fit(x2_pca,y2_train)\n",
    "print(reg.score(x2_pca,y2_train))\n",
    "\n",
    "# Ex1\n",
    "x_pca = pca_fit.transform(x)\n",
    "sink_y_pre = pcreg.predict(x_pca)\n",
    "rmse = np.sqrt(mean_squared_error(y2, sink_y_pre))\n",
    "print('RMSE for kitchen sink predictor: '+ str(rmse))\n",
    "x2_test_pca = pca_fit.transform(x2_test)\n",
    "test_y_pre = pcreg.predict(x2_test_pca)\n",
    "test_rmse = np.sqrt(mean_squared_error(y2_test, test_y_pre))\n",
    "print('Performance on test set: ' + str(test_rmse))\n",
    "\n",
    "# Ex2\n",
    "x_0211_pca = pca_fit.transform(x_0211)\n",
    "test_y_0211_pre = pcreg.predict(x_0211_pca)\n",
    "test_rmse_0211 = np.sqrt(mean_squared_error(y2_0211, test_y_0211_pre))\n",
    "print('Performance on 02-11 dataset: ' + str(test_rmse_0211))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e96ab0",
   "metadata": {},
   "source": [
    "# Exercise 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "9517deb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== Subset Selection ======\n",
      "=== ln_y ===\n",
      "('gcf', 'ext_bal', 'fem_emp', 'inf_mort', 'lexp', 'age_dep_young', 'urban', 'yrsoffc', 'military', 'competitiveness_leg', 'parliamentary', 'stability', 'effectiveness', 'regulation', 'corruption')\n",
      "0.8987270727399517\n",
      "MAE for naive predictor: 2.220446049250313e-16\n",
      "RMSE for kitchen sink predictor: 0.2694374558652285\n",
      "Performance on test set: 0.3247875479256552\n",
      "=== growth ===\n",
      "('gcf', 'ext_bal', 'inflation', 'tfr', 'yrsoffc', 'parliamentary', 'voice', 'effectiveness')\n",
      "-0.04344698790079064\n",
      "MAE for naive predictor: 1.3877787807814457e-17\n",
      "RMSE for kitchen sink predictor: 0.020177753791363138\n",
      "Performance on test set: 0.01864901908698803\n",
      "====== Ridge Regression ======\n",
      "=== ln_y ===\n",
      "Best score: 0.8952336149717841\n",
      "Best alpha: 20.09233002565047\n",
      "MAE for naive predictor: 6.938893903907228e-17\n",
      "RMSE for kitchen sink predictor: 0.27304195896211786\n",
      "Performance on test set: 0.2997926643039591\n",
      "=== growth ===\n",
      "Best score: -0.1798079791124283\n",
      "Best alpha: 61.35907273413173\n",
      "MAE for naive predictor: 1.3877787807814457e-17\n",
      "RMSE for kitchen sink predictor: 0.02064187576287524\n",
      "Performance on test set: 0.01782078422672112\n",
      "====== Principal Components ======\n",
      "=== ln_y ===\n",
      "0.9455366536907261\n",
      "RMSE for kitchen sink predictor: 0.2534726613711429\n",
      "Performance on test set: 0.3078233235032711\n",
      "=== growth ===\n",
      "0.5280877581603838\n",
      "RMSE for kitchen sink predictor: 0.01900685382494538\n",
      "Performance on test set: 0.02132372048522742\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../raw/growthdata02_11.csv\",index_col=0)\n",
    "x = df.drop(['iso3','ln_y','growth'], axis=1)\n",
    "y1 = df['ln_y']\n",
    "y2 = df['growth']\n",
    "\n",
    "# get train set and test set\n",
    "x1_train,x1_test,y1_train,y1_test = train_test_split(x,y1,test_size = 0.2)\n",
    "x2_train,x2_test,y2_train,y2_test = train_test_split(x,y2,test_size = 0.2)\n",
    "\n",
    "reg = linear_model.LinearRegression()\n",
    "\n",
    "############################## Subset Selection ###################################\n",
    "print (\"====== Subset Selection ======\")\n",
    "print (\"=== ln_y ===\")\n",
    "# ln_y\n",
    "sfs = SequentialFeatureSelector(reg,k_features = (2,x1_train.shape[1]),forward=True, floating=False, cv=10\n",
    "                               # ,verbose=2         # show the process\n",
    "                               )\n",
    "sfs.fit(x1_train,y1_train)\n",
    "selected_features = list(sfs.k_feature_names_)\n",
    "print(sfs.k_feature_names_)\n",
    "print(sfs.k_score_)\n",
    "x1_selected = x1_train[selected_features]\n",
    "reg.fit(x1_selected,y1_train)\n",
    "mean = pd.DataFrame(np.mean(x1_selected)).transpose()\n",
    "naive_y_pre = reg.predict(mean)\n",
    "mae = abs(naive_y_pre[0] - np.mean(y1_train))\n",
    "print('MAE for naive predictor: ' + str(mae))\n",
    "sink_y_pre = reg.predict(x[selected_features])\n",
    "sink_rmse = np.sqrt(mean_squared_error(y1, sink_y_pre))\n",
    "print('RMSE for kitchen sink predictor: '+ str(sink_rmse))\n",
    "test_y_pre = reg.predict(x1_test[selected_features])\n",
    "test_rmse = np.sqrt(mean_squared_error(y1_test, test_y_pre))\n",
    "print('Performance on test set: ' + str(test_rmse))\n",
    "\n",
    "print (\"=== growth ===\")\n",
    "# growth\n",
    "sfs.fit(x2_train,y2_train)\n",
    "print(sfs.k_feature_names_)\n",
    "print(sfs.k_score_)\n",
    "x2_selected = x2_train[selected_features]\n",
    "reg.fit(x2_selected,y2_train)\n",
    "mean = pd.DataFrame(np.mean(x2_selected)).transpose()\n",
    "naive_y_pre = reg.predict(mean)\n",
    "mae = abs(naive_y_pre[0] - np.mean(y2_train))\n",
    "print('MAE for naive predictor: ' + str(mae))\n",
    "sink_y_pre = reg.predict(x[selected_features])\n",
    "rmse = np.sqrt(mean_squared_error(y2, sink_y_pre))\n",
    "print('RMSE for kitchen sink predictor: '+ str(rmse))\n",
    "test_y_pre = reg.predict(x2_test[selected_features])\n",
    "test_rmse = np.sqrt(mean_squared_error(y2_test, test_y_pre))\n",
    "print('Performance on test set: ' + str(test_rmse))\n",
    "\n",
    "############################## Ridge Regression ###################################\n",
    "print (\"====== Ridge Regression ======\")\n",
    "print (\"=== ln_y ===\")\n",
    "alphas = np.logspace(0, 3, 100) \n",
    "ridge_scores = []\n",
    "\n",
    "for alpha in alphas:\n",
    "    ridge = linear_model.Ridge(alpha=alpha)\n",
    "    scores = cross_val_score(ridge, x1_train, y1_train, cv=10)\n",
    "    ridge_scores.append(np.mean(scores))\n",
    "best_alpha_index = np.argmax(ridge_scores)  \n",
    "best_alpha = alphas[best_alpha_index]  \n",
    "best_score = ridge_scores[best_alpha_index] \n",
    "print('Best score: ' + str(best_score))\n",
    "print('Best alpha: ' + str(best_alpha))\n",
    "ridge = linear_model.Ridge(alpha = best_alpha)\n",
    "ridge.fit(x1_train, y1_train)\n",
    "mean = pd.DataFrame(np.mean(x1_train)).transpose()\n",
    "naive_y_pre = ridge.predict(mean)\n",
    "mae = abs(naive_y_pre[0] - np.mean(y1_train))\n",
    "print('MAE for naive predictor: ' + str(mae))\n",
    "sink_y_pre = ridge.predict(x)\n",
    "rmse = np.sqrt(mean_squared_error(y1, sink_y_pre))\n",
    "print('RMSE for kitchen sink predictor: '+ str(rmse))\n",
    "test_y_pre = ridge.predict(x1_test)\n",
    "test_rmse = np.sqrt(mean_squared_error(y1_test, test_y_pre))\n",
    "print('Performance on test set: ' + str(test_rmse))\n",
    "\n",
    "print (\"=== growth ===\")\n",
    "ridge_scores = []\n",
    "for alpha in alphas:\n",
    "    ridge = linear_model.Ridge(alpha=alpha)\n",
    "    scores = cross_val_score(ridge, x2_train, y2_train, cv=10)\n",
    "    ridge_scores.append(np.mean(scores))\n",
    "best_alpha_index = np.argmax(ridge_scores)  \n",
    "best_alpha = alphas[best_alpha_index]  \n",
    "best_score = ridge_scores[best_alpha_index] \n",
    "print('Best score: ' + str(best_score))\n",
    "print('Best alpha: ' + str(best_alpha))\n",
    "ridge = linear_model.Ridge(alpha = best_alpha)\n",
    "ridge.fit(x2_train, y2_train)\n",
    "mean = pd.DataFrame(np.mean(x2_train)).transpose()\n",
    "naive_y_pre = ridge.predict(mean)\n",
    "mae = abs(naive_y_pre[0] - np.mean(y2_train))\n",
    "print('MAE for naive predictor: ' + str(mae))\n",
    "sink_y_pre = ridge.predict(x)\n",
    "rmse = np.sqrt(mean_squared_error(y2, sink_y_pre))\n",
    "print('RMSE for kitchen sink predictor: '+ str(rmse))\n",
    "test_y_pre = ridge.predict(x2_test)\n",
    "test_rmse = np.sqrt(mean_squared_error(y2_test, test_y_pre))\n",
    "print('Performance on test set: ' + str(test_rmse))\n",
    "\n",
    "############################## Principal Components ###################################\n",
    "print (\"====== Principal Components ======\")\n",
    "print (\"=== ln_y ===\")\n",
    "pca = PCA(copy = True)\n",
    "pca_fit = pca.fit(x1_train)\n",
    "x1_pca = pca.fit_transform(x1_train)\n",
    "reg = linear_model.LinearRegression()\n",
    "pcreg = reg.fit(x1_pca,y1_train)\n",
    "print(reg.score(x1_pca,y1_train))\n",
    "x_pca = pca_fit.transform(x)\n",
    "sink_y_pre = pcreg.predict(x_pca)\n",
    "rmse = np.sqrt(mean_squared_error(y1, sink_y_pre))\n",
    "print('RMSE for kitchen sink predictor: '+ str(rmse))\n",
    "x1_test_pca = pca_fit.transform(x1_test)\n",
    "test_y_pre = pcreg.predict(x1_test_pca)\n",
    "test_rmse = np.sqrt(mean_squared_error(y1_test, test_y_pre))\n",
    "print('Performance on test set: ' + str(test_rmse))\n",
    "\n",
    "print (\"=== growth ===\")\n",
    "pca_fit = pca.fit(x2_train)\n",
    "x2_pca = pca.fit_transform(x2_train)\n",
    "reg = linear_model.LinearRegression()\n",
    "pcreg = reg.fit(x2_pca,y2_train)\n",
    "print(reg.score(x2_pca,y2_train))\n",
    "x_pca = pca_fit.transform(x)\n",
    "sink_y_pre = pcreg.predict(x_pca)\n",
    "rmse = np.sqrt(mean_squared_error(y2, sink_y_pre))\n",
    "print('RMSE for kitchen sink predictor: '+ str(rmse))\n",
    "x2_test_pca = pca_fit.transform(x2_test)\n",
    "test_y_pre = pcreg.predict(x2_test_pca)\n",
    "test_rmse = np.sqrt(mean_squared_error(y2_test, test_y_pre))\n",
    "print('Performance on test set: ' + str(test_rmse))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
